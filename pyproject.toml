[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "chain"
version = "3.0.0"
description = "A lightweight, unified framework for building LLM applications"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    # Core dependencies
    "pydantic",
    "jinja2", 
    "rich",
    "tiktoken",
    "instructor",
    "tinydb",
    "python-dotenv",
    # LLM Provider SDKs
    "openai",
    "anthropic", 
    "google-generativeai",
    "ollama",
    # Audio/Image Processing
    "pydub",
    "pillow",
    "soundfile",
    # Machine Learning/AI
    "torch==2.7.1",  # Pinned for your GPU setup
    "transformers",
    "huggingface_hub",
    # Web/HTTP
    "requests",
    "fastapi",
    "uvicorn",
    # Data Processing
    "numpy",
]

[project.optional-dependencies]
dev = [
    "pytest",
    "pytest-asyncio",
]
tts = [
    # Add when these become available on PyPI
    # "ChatTTS",
    # "bark", 
    # "elevenlabs",
]
full = [
    "pandas",
    "matplotlib", 
    "tensorflow",
    "mammoth",
]

[project.scripts]
update = "Chain.scripts.update_modelstore:main"
update_ollama = "Chain.scripts.update_ollama_list:main"
models = "Chain.scripts.models_cli:main"
chat = "Chain.chat.chat:main"
chainserver = "Chain.api.server.run:main"

[tool.pytest.ini_options]
addopts = "-v -s --tb=short --no-header --showlocals --pdb -x"
log_cli = true
log_cli_level = "INFO"

# Hatchling configuration (replaces setuptools.packages.find)
[tool.hatch.build.targets.wheel]
packages = ["Chain"]




















[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "chain"
version = "0.1.0"
description = "A lightweight, unified framework for building LLM applications"
authors = [
    {name = "Your Name", email = "your.email@example.com"}
]
readme = "README.md"
requires-python = ">=3.8"
dependencies = [
    # Core dependencies - let uv resolve versions
    "pydantic",
    "jinja2", 
    "rich",
    "tiktoken",
    "instructor",
    "tinydb",
    "python-dotenv",
    
    # LLM Provider SDKs
    "openai",
    "anthropic", 
    "google-generativeai",
    "ollama",
    
    # Audio/Image Processing
    "pydub",
    "pillow",
    "soundfile",
    
    # TTS/Audio Generation
    "elevenlabs",
    # "ChatTTS",  # Add if available on PyPI
    # "bark",     # Add if available on PyPI
    # "chatterbox", # Add if available on PyPI
    
    # Machine Learning/AI - PIN TORCH
    "torch==2.7.1",  # Pinned for CUDA 12.8 + RTX 5090 compatibility
    "transformers",
    "huggingface_hub",
    "tensorflow",
    
    # Data Processing
    "pandas",
    "numpy",
    "matplotlib",
    
    # Web/HTTP
    "requests",
    "fastapi",
    "uvicorn",
    
    # Optional dependencies
    "mammoth",
]

[project.optional-dependencies]
dev = [
    "pytest",
    "pytest-asyncio",
]
audio = [
    # Add audio-specific dependencies here if they become available
]

[project.urls]
Homepage = "https://github.com/yourusername/Chain"
Repository = "https://github.com/yourusername/Chain"

[tool.hatch.build.targets.wheel]
packages = ["Chain"]




[project]
name = "chain"
version = "3.0.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.12"
dependencies = []

[tool.pytest.ini_options]
# Show local variables in tracebacks, drop into pdb on failure, maxfail = 1
addopts = "-v -s --tb=short --no-header --showlocals --pdb -x"
# Logging configuration
log_cli = true
log_cli_level = "INFO"
# log_cli_format = "%(asctime)s [%(levelname)8s] %(name)s: %(message)s"
# log_cli_date_format = "%Y-%m-%d %H:%M:%S"

[project.scripts]
update = "Chain.scripts.update_modelstore:main"
update_ollama = "Chain.scripts.update_ollama_list:main"
models = "Chain.scripts.models_cli:main"
chat = "Chain.chat.chat:main"
chainserver = "Chain.api.server.run:main"

[tool.setuptools.packages.find]
include = ["Chain*"]
